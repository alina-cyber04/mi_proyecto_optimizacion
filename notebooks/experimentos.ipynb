{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0223442",
   "metadata": {},
   "source": [
    "# Experimentos de optimización: $f(x,y)=y^2 + \\log(1+x^2)$\n",
    "\n",
    "**Autor:** Alina María de la Noval Armenteros  \n",
    "**Grupo:** C-311  \n",
    "\n",
    "\n",
    "**Objetivo:** Aplicar los métodos Descenso por Gradiente con Armijo y BFGS (Cuasi-Newton) a la función $f(x,y)=y^2 + \\log(1+x^2)$, comparar su comportamiento en términos de convergencia, número de iteraciones, tiempo y sensibilidad al punto inicial, y documentar conclusiones técnicas.\n",
    "\n",
    "**Resumen breve:** Esta función combina un término cuadrático en $y$ con un término logarítmico en $x$; la diferencia en curvatura entre las direcciones $x$ y $y$ la hace adecuada para comparar la eficacia de métodos de primer y segundo orden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e426a2a",
   "metadata": {},
   "source": [
    "## Descripción teórica del problema\n",
    "\n",
    "Función objetivo: $$f(x,y)=y^2 + \\log(1+x^2).$$\n",
    "\n",
    "- Dominio: definida para todo $(x,y)\\in\\mathbb{R}^2$ ya que $1+x^2>0$ para todo $x$.\n",
    "- Descomposición: la función se puede escribir como suma de funciones univariadas, $f(x,y)=g(x)+h(y)$ con $g(x)=\\log(1+x^2)$ y $h(y)=y^2$. Esto facilita el análisis teórico y numérico.\n",
    "- Regularidad: ambas componentes son $C^{\\infty}$ en el dominio, por lo que $f\\in C^{\\infty}(\\mathbb{R}^2)$; es válido usar métodos que requieran gradiente y aproximaciones de la Hessiana.\n",
    "\n",
    "**Gradiente:**\n",
    "$$\\nabla f(x,y)=\\begin{pmatrix}\\dfrac{2x}{1+x^2}\\\\2y\\end{pmatrix}.$$\n",
    "\n",
    "**Hessiano:**\n",
    "$$\\nabla^2 f(x,y)=\\begin{pmatrix}\\dfrac{2(1-x^2)}{(1+x^2)^2} & 0\\\\0 & 2\\end{pmatrix}.$$\n",
    "\n",
    "- Observación sobre convexidad: la componente $(2(1-x^2)/(1+x^2)^2)$ cambia de signo: es positiva para $|x|<1$, cero en $|x|=1$ y negativa para $|x|>1$. Por tanto, el Hessiano no es globalmente semidefinido positivo y la función no es convexa globalmente; sin embargo, localmente alrededor del origen muestra comportamiento convexo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7fc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from optimizacion import gradient_descent_armijo, bfgs\n",
    "from optimizacion.line_search import backtracking_armijo\n",
    "from optimizacion.util_json import run_and_save_experiments, load_experiments_from_json\n",
    "from optimizacion.graficos import plot_convergence, plot_final_vs_iters, plot_trajectory_2d\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Función objetivo. `x` es array-like [x, y].\n",
    "    Devuelve escalar f(x).\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    xv = float(x[0])\n",
    "    yv = float(x[1])\n",
    "    return yv**2 + np.log(1.0 + xv**2)\n",
    "\n",
    "def grad(x):\n",
    "    \"\"\"Gradiente de f: devuelve array [df/dx, df/dy].\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    xv = float(x[0])\n",
    "    yv = float(x[1])\n",
    "    dfdx = (2.0 * xv) / (1.0 + xv**2)\n",
    "    dfdy = 2.0 * yv\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac1821",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['gd', 'bfgs']  \n",
    "# Puntos actualizados para obtener resultados más diferenciados en las gráficas\n",
    "points = [np.array([0.05,0.02]), np.array([0.9,0.0]), np.array([2.5,0.0]), np.array([0.0,2.5]), np.array([-3.0,1.5]), np.array([5.0,-2.0])]\n",
    "\n",
    "tolerance = 1e-6\n",
    "maxiter = 500\n",
    "\n",
    "run_configs = []\n",
    "for alg in algorithms:\n",
    "    for x0 in points:\n",
    "        cfg = {\n",
    "            'algorithm': alg,\n",
    "            'x0': x0,\n",
    "            'tolerance': tolerance,\n",
    "            'line_search': backtracking_armijo if alg == 'gd' else None,\n",
    "            'maxiter': maxiter\n",
    "        }\n",
    "        run_configs.append(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6382b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear nombres a funciones (coincide con 'algorithm' en run_configs)\n",
    "algorithm_fn_map = {\n",
    "    'gd': gradient_descent_armijo,\n",
    "    'bfgs': bfgs\n",
    "}\n",
    "\n",
    "# Ejecutar y guardar resultados (guardará en data/resultados/experimentos.json)\n",
    "output_file = 'data/resultados/experimentos.json'\n",
    "experiment_data = run_and_save_experiments(run_configs, algorithm_fn_map, filename=output_file, f=f, grad=grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e9fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar resultados desde JSON para análisis/plotting\n",
    "data = load_experiments_from_json('data/resultados/experimentos.json')\n",
    "experiments = data.get('experiments', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficación: convergencia, comparación y trayectorias individuales\n",
    "import os\n",
    "os.makedirs('data/resultados', exist_ok=True)\n",
    "plot_convergence(experiments, filename='data/resultados/convergencia.png', group_by='algorithm', smooth_window=5, decimate=2, legend_outside=True, legend_fontsize='x-small', compact_labels=True)\n",
    "plot_final_vs_iters(experiments, filename='data/resultados/final_vs_iters.png')\n",
    "if experiments:\n",
    "    exp0 = experiments[0]\n",
    "    plot_trajectory_2d(exp0, filename='data/resultados/trayectoria_exp1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870c9a9",
   "metadata": {},
   "source": [
    "## Análisis de resultados y conclusiones\n",
    "\n",
    "Interpreta las gráficas y la tabla de resultados atendiendo a los siguientes puntos técnicos:\n",
    "\n",
    "1. Convergencia: compara número de iteraciones y tiempo (CPU) entre GD-Armijo y BFGS. Indica si alguna corrida no alcanzó la tolerancia antes de `maxiter` y reporta el estado final.\n",
    "\n",
    "2. Calidad de la solución: compara $f_{final}$ y $\\|\\nabla f\\|_{final}$ entre algoritmos y puntos iniciales; identifica si hay soluciones con valores significativamente distintos.\n",
    "\n",
    "3. Sensibilidad al punto inicial: analiza cómo cambian resultados y número de iteraciones con diferentes $x_0$; comenta si hay regiones problemáticas (p. ej. |x|>1 con curvatura negativa en x).\n",
    "\n",
    "4. Efecto de la curvatura: observa comportamientos típicos (pasos pequeños en $x$, oscilaciones) ligados a la variación de la componente Hessiana en $x$.\n",
    "\n",
    "5. Recomendaciones: estima cuándo usar GD-Armijo (simples, bajo coste por iteración) y cuándo BFGS (menos iteraciones, mejor en problemas con anisotropía de curvatura). Considera L-BFGS para dimensiones mayores o Newton si la Hessiana es accesible.\n",
    "\n",
    "Sugerencia para el informe final:\n",
    "- Incluir una tabla resumen con columnas: algoritmo, x0, tol, iters, tiempo, f_final, grad_norm, status.\n",
    "- Adjuntar las figuras guardadas en `data/resultados/` y comentar patrones relevantes.\n",
    "- Concluir con una recomendación clara: cuándo preferir cada método y por qué."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
